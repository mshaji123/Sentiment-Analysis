{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing sentiment polarity\n",
    "#### Analysing sentiment polarity of reddit using different models and comparing their accuracy, precision, recall and f1 score to determine the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0KyX7MxGAZ1",
    "outputId": "d1b790e0-4b46-48b6-f894-3b670d97e10d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mathe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtb2fNFYK1c2"
   },
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9YghjmO6JpPp"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_train.json\")\n",
    "validation_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_validation.json\")\n",
    "test_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>majority_type</th>\n",
       "      <th>is_first_post</th>\n",
       "      <th>post_depth</th>\n",
       "      <th>in_reply_to</th>\n",
       "      <th>sentiment.polarity</th>\n",
       "      <th>sentiment.subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relationships</td>\n",
       "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
       "      <td>t1_cy7f317</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>Melodrama_</td>\n",
       "      <td>It's a sad realization, isn't it?</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>t1_cy7erc5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relationships</td>\n",
       "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
       "      <td>t1_cy7hlyf</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>Melodrama_</td>\n",
       "      <td>I told her a couple of minutes ago that I didn...</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>t1_cy7erc5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.483631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relationships</td>\n",
       "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
       "      <td>t1_cy7etrr</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>TreatYoSelves</td>\n",
       "      <td>Leeches don't make good friends.</td>\n",
       "      <td>answer</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_3xshx9</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
       "      <td>t1_cy7hhpq</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>Melodrama_</td>\n",
       "      <td>I just ended it. Apparently she wasn't a good ...</td>\n",
       "      <td>elaboration</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>t1_cy7etrr</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relationships</td>\n",
       "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
       "      <td>t1_cy7q0qg</td>\n",
       "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
       "      <td>TreatYoSelves</td>\n",
       "      <td>Good for you!  Make sure you stick with it.</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>t1_cy7hhpq</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit                                              title  \\\n",
       "0  relationships  My Friend/Crush [22/F] acting weird after I [2...   \n",
       "1  relationships  My Friend/Crush [22/F] acting weird after I [2...   \n",
       "2  relationships  My Friend/Crush [22/F] acting weird after I [2...   \n",
       "3  relationships  My Friend/Crush [22/F] acting weird after I [2...   \n",
       "4  relationships  My Friend/Crush [22/F] acting weird after I [2...   \n",
       "\n",
       "           id                                                url  \\\n",
       "0  t1_cy7f317  https://www.reddit.com/r/relationships/comment...   \n",
       "1  t1_cy7hlyf  https://www.reddit.com/r/relationships/comment...   \n",
       "2  t1_cy7etrr  https://www.reddit.com/r/relationships/comment...   \n",
       "3  t1_cy7hhpq  https://www.reddit.com/r/relationships/comment...   \n",
       "4  t1_cy7q0qg  https://www.reddit.com/r/relationships/comment...   \n",
       "\n",
       "          author                                               body  \\\n",
       "0     Melodrama_                  It's a sad realization, isn't it?   \n",
       "1     Melodrama_  I told her a couple of minutes ago that I didn...   \n",
       "2  TreatYoSelves                  Leeches don't make good friends.    \n",
       "3     Melodrama_  I just ended it. Apparently she wasn't a good ...   \n",
       "4  TreatYoSelves       Good for you!  Make sure you stick with it.    \n",
       "\n",
       "  majority_type  is_first_post  post_depth in_reply_to sentiment.polarity  \\\n",
       "0                        False           2  t1_cy7erc5           negative   \n",
       "1   elaboration          False           2  t1_cy7erc5            neutral   \n",
       "2        answer          False           1   t3_3xshx9           positive   \n",
       "3   elaboration          False           2  t1_cy7etrr           positive   \n",
       "4  appreciation          False           3  t1_cy7hhpq           positive   \n",
       "\n",
       "   sentiment.subjectivity  \n",
       "0                1.000000  \n",
       "1                0.483631  \n",
       "2                0.600000  \n",
       "3                0.475000  \n",
       "4                0.744444  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer              5207\n",
       "question            2016\n",
       "elaboration         1638\n",
       "                    1100\n",
       "appreciation         674\n",
       "agreement            406\n",
       "disagreement         356\n",
       "humor                275\n",
       "other                187\n",
       "negativereaction     157\n",
       "announcement         122\n",
       "Name: majority_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['majority_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "As a support main the current state of the summoner spells is awesome!                                                                                                    41\n",
       "there are 32,966 people here on starcraft...that's 12,966 more than IdrA needs tomorrow night. Reddit, you know what to do!                                               41\n",
       "iot, please fix the /r chat bug.                                                                                                                                          41\n",
       "movie night: i'm looking for a horror/psychological thriller that will completely surprise me. suggestions?                                                               40\n",
       "Reddit, what are the best HL2 mods?                                                                                                                                       40\n",
       "                                                                                                                                                                          ..\n",
       "These are problems we face in the League of legends....                                                                                                                    3\n",
       "Do you think the ribbon systems needs a rework?                                                                                                                            3\n",
       "what was your moment of clarity?                                                                                                                                           3\n",
       "Me [22 M] with my crush/good friend [34 F] - after two months now, we nearly dated but we made it clear between each other it won't work. Excruciating emotional pain.     3\n",
       "I tell my dealer that I'm picking up for a friend sometimes because I don't want him to know how much I really smoke.                                                      2\n",
       "Name: title, Length: 1164, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment.polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12138</td>\n",
       "      <td>12138</td>\n",
       "      <td>12138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1164</td>\n",
       "      <td>11678</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>As a support main the current state of the sum...</td>\n",
       "      <td></td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>41</td>\n",
       "      <td>348</td>\n",
       "      <td>7679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title   body  \\\n",
       "count                                               12138  12138   \n",
       "unique                                               1164  11678   \n",
       "top     As a support main the current state of the sum...          \n",
       "freq                                                   41    348   \n",
       "\n",
       "       sentiment.polarity  \n",
       "count               12138  \n",
       "unique                  5  \n",
       "top               neutral  \n",
       "freq                 7679  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['title','body', 'sentiment.polarity']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 348\n",
       "[deleted]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         69\n",
       "**Attention!** Please keep in mind that the OP of this thread has chosen to mark this post with the **[Serious] replies only** tag, therefore any replies that are jokes, puns, off-topic, or are otherwise non-contributory will be removed.\\n\\nIf you see others posting comments that violate this tag, please report them to the mods! \\n\\nThanks for your cooperation and enjoy the discussion!\\n\\n\\n*[I am a bot](/r/AutoModerator/comments/q11pu/what_is_automoderator/), and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose?to=%2Fr%2FAskReddit) if you have any questions or concerns.*      6\n",
       "yes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                4\n",
       "**Attention!** Please keep in mind that the OP of this thread has chosen to mark this post with the **[Serious] replies only** tag, therefore any replies that are jokes, puns, off-topic, or are otherwise non-contributory will be removed.\\n\\nIf you see others posting comments that violate this tag, please report them to the mods! \\n\\nThanks for your cooperation and enjoy the discussion!\\n                                                                                                                                                                                                                                                             4\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ... \n",
       "What do you mean by \"right\"? Are you asking if we think it is necessary or if we think it's a good thing?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       "Thats exactly where my mind went when I saw this design. Not even we can get away from this social rank structure.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "Was around lvl 15-20 in early/mid s2, every role but mid was taken and Ahri was free to play, so I decided to give her a try. \\n\\nLoved the way her spells synergised with each other and how fun, rewarding, mobile and versatile she was.\\n\\n4 seasons and a few months later and she's still pretty much the only champion I play mid.                                                                                                                                                                                                                                                                                                                          1\n",
       "Tis in the adversity that the true zealot reveals himself for there is no glory in an easy victory.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "The worst case scenario for a mac is simply a white screen, with a folder and a question mark in the center of it. That's the royally fucked screen.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\n",
       "Name: body, Length: 11678, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['body'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Sentiment polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral          7679\n",
      "positive         3231\n",
      "negative          878\n",
      "very positive     253\n",
      "very negative      97\n",
      "Name: sentiment.polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (train_data['sentiment.polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral          2514\n",
      "positive         1102\n",
      "negative          282\n",
      "very positive      86\n",
      "very negative      32\n",
      "Name: sentiment.polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (test_data['sentiment.polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral          1961\n",
      "positive          845\n",
      "negative          215\n",
      "very positive      73\n",
      "very negative      15\n",
      "Name: sentiment.polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (validation_data['sentiment.polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGNfdDZ5LFyR"
   },
   "source": [
    "## Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Bditt2QyMfmu"
   },
   "outputs": [],
   "source": [
    "stopwords = ['i','me', 'my','myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours','yourself', 'yourselves', 'he',\n",
    " 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\",'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
    " 'this', 'that', \"that'll\",'these', 'those', 'am', 'is', 'are', 'was', 'were', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for',\n",
    " 'with', 'about', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again',\n",
    " 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same',\n",
    " 'so', 'than', 'too', 'very', 's', 't', 'just', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ma'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kPT1a2FpLVvq"
   },
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    porter = PorterStemmer()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation]) #Removed punc\n",
    "    text = ' '.join([word.lower() for word in text.split() if word.lower() not in stopwords]) #removed stopwords\n",
    "    text = [porter.stem(word) for word in text.split()] #Stemmin\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "The CountVectorizer from Scikit-learn is used to turn a set of text documents into a vector of term/token counts. It also allows text data to be pre-processed before being converted into a vector format. Because of this, it's a text feature representation module with a lot of flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ElKRDVglPuog"
   },
   "outputs": [],
   "source": [
    "vec_transformer = CountVectorizer(analyzer=text_process)\n",
    "vec_transformer.fit(train_data['body'])\n",
    "onehot_train = vec_transformer.transform(train_data['body'])\n",
    "onehot_test = vec_transformer.transform(test_data['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "Term Frequency — Inverse Document Frequency (TF-IDF) is a statistic that attempts to better identify the importance of a word in a document while also considering its relationship to other documents in the same corpus.\n",
    "\n",
    "This is done by counting the number of times a term appears in a document as well as the number of times the same word appears in other documents in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9EyuhgAsQuUE"
   },
   "outputs": [],
   "source": [
    "tfidf_trans = TfidfTransformer()\n",
    "tfidf_trans.fit(onehot_train)\n",
    "tfidf_train = tfidf_trans.transform(onehot_train)\n",
    "tfidf_test = tfidf_trans.transform(onehot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model with sklearns Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iOm1sDxEQ297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.00      0.00      0.00       282\n",
      "      neutral       0.63      1.00      0.77      2514\n",
      "     positive       0.00      0.00      0.00      1102\n",
      "very negative       0.00      0.00      0.00        32\n",
      "very positive       0.00      0.00      0.00        86\n",
      "\n",
      "     accuracy                           0.63      4016\n",
      "    macro avg       0.13      0.20      0.15      4016\n",
      " weighted avg       0.39      0.63      0.48      4016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent')\n",
    "dummy_model.fit(train_data['body'], train_data['sentiment.polarity'])\n",
    "preds = dummy_model.predict(test_data['body'])\n",
    "print(classification_report(test_data['sentiment.polarity'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "95iY8W-IRPcC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.08      0.08      0.08       282\n",
      "      neutral       0.63      0.65      0.63      2514\n",
      "     positive       0.28      0.26      0.27      1102\n",
      "very negative       0.00      0.00      0.00        32\n",
      "very positive       0.00      0.00      0.00        86\n",
      "\n",
      "     accuracy                           0.48      4016\n",
      "    macro avg       0.20      0.20      0.20      4016\n",
      " weighted avg       0.47      0.48      0.48      4016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_model2 = DummyClassifier(strategy='stratified')\n",
    "dummy_model2.fit(train_data['body'], train_data['sentiment.polarity'])\n",
    "preds = dummy_model2.predict(test_data['body'])\n",
    "print(classification_report(test_data['sentiment.polarity'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training One hot vectorised data with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "o1nHixWBRkxo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.35      0.20      0.25       282\n",
      "      neutral       0.76      0.86      0.81      2514\n",
      "     positive       0.68      0.58      0.63      1102\n",
      "very negative       0.33      0.06      0.11        32\n",
      "very positive       0.46      0.24      0.32        86\n",
      "\n",
      "     accuracy                           0.72      4016\n",
      "    macro avg       0.52      0.39      0.42      4016\n",
      " weighted avg       0.70      0.72      0.70      4016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_onehot_model = LogisticRegression(max_iter = 1000)\n",
    "lr_onehot_model.fit(onehot_train, train_data['sentiment.polarity'])\n",
    "pred = lr_onehot_model.predict(onehot_test)\n",
    "print(classification_report(test_data['sentiment.polarity'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training TF-IDF vector with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "68n4s7sXRpMD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.66      0.11      0.19       282\n",
      "      neutral       0.74      0.93      0.82      2514\n",
      "     positive       0.73      0.51      0.60      1102\n",
      "very negative       0.50      0.03      0.06        32\n",
      "very positive       0.57      0.05      0.09        86\n",
      "\n",
      "     accuracy                           0.73      4016\n",
      "    macro avg       0.64      0.33      0.35      4016\n",
      " weighted avg       0.72      0.73      0.70      4016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_model = LogisticRegression(max_iter = 1000)\n",
    "lr_tfidf_model.fit(tfidf_train, train_data['sentiment.polarity'])\n",
    "pred = lr_tfidf_model.predict(tfidf_test)\n",
    "print(classification_report(test_data['sentiment.polarity'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training one hot vector with SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "VmG-Dn8XRuPF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.58      0.02      0.05       282\n",
      "      neutral       0.71      0.95      0.82      2514\n",
      "     positive       0.75      0.44      0.55      1102\n",
      "very negative       0.00      0.00      0.00        32\n",
      "very positive       0.00      0.00      0.00        86\n",
      "\n",
      "     accuracy                           0.72      4016\n",
      "    macro avg       0.41      0.28      0.28      4016\n",
      " weighted avg       0.69      0.72      0.67      4016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf_model = SVC(kernel='rbf')\n",
    "svc_tfidf_model.fit(onehot_train, train_data['sentiment.polarity'])\n",
    "pred = svc_tfidf_model.predict(onehot_test)\n",
    "print(classification_report(test_data['sentiment.polarity'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "EzZf-hWjR3bX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.52      0.23      0.32       282\n",
      "      neutral       0.76      0.90      0.83      2514\n",
      "     positive       0.73      0.58      0.65      1102\n",
      "very negative       0.00      0.00      0.00        32\n",
      "very positive       0.59      0.19      0.28        86\n",
      "\n",
      "     accuracy                           0.75      4016\n",
      "    macro avg       0.52      0.38      0.42      4016\n",
      " weighted avg       0.73      0.75      0.73      4016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mathe\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "my_tfidf_model = StackingClassifier([('lr', LogisticRegression(max_iter = 1000)), ('cnb', ComplementNB())])\n",
    "my_tfidf_model.fit(tfidf_train, train_data['sentiment.polarity'])\n",
    "pred = my_tfidf_model.predict(tfidf_test)\n",
    "print(classification_report(test_data['sentiment.polarity'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgGZ-DTMT7SA"
   },
   "source": [
    "### Finding Best parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "lY8T-1Z-T748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n",
      "Best parameter (CV score=0.733):\n",
      "{'lr__C': 10, 'lr__class_weight': None, 'tfidf__max_features': 5000, 'tfidf__sublinear_tf': True}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('tfidf', TfidfVectorizer()), ('lr', LogisticRegression(max_iter = 1000))])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'tfidf__max_features': [None, 500, 5000, 50000],\n",
    "    'lr__C': [0.01,0.1,1,10],\n",
    "    'lr__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=2, scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "search.fit(train_data['body'], train_data['sentiment.polarity'])\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "zMG1i4tvWzuR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.58      0.32      0.41       282\n",
      "      neutral       0.80      0.88      0.84      2514\n",
      "     positive       0.72      0.67      0.69      1102\n",
      "very negative       0.67      0.25      0.36        32\n",
      "very positive       0.53      0.21      0.30        86\n",
      "\n",
      "     accuracy                           0.76      4016\n",
      "    macro avg       0.66      0.47      0.52      4016\n",
      " weighted avg       0.75      0.76      0.75      4016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = search.predict(test_data['body'])\n",
    "print(classification_report(test_data['sentiment.polarity'], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtTCBuWnXIN7"
   },
   "source": [
    "### Training the best model with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "6aYvZCIWX4yG"
   },
   "outputs": [],
   "source": [
    "sublinear_tf = True\n",
    "max_features = 5000\n",
    "C = 10\n",
    "class_weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "WKo5y1l2XI6f"
   },
   "outputs": [],
   "source": [
    "tfidf_trans = TfidfVectorizer(analyzer=text_process, sublinear_tf=sublinear_tf, max_features=max_features)\n",
    "tfidf_trans.fit(train_data['body'] + train_data['title'] + train_data['majority_type'])\n",
    "tfidf_train = tfidf_trans.transform(train_data['body'] + train_data['title'] + train_data['majority_type'])\n",
    "tfidf_test = tfidf_trans.transform(test_data['body'] + test_data['title'] + test_data['majority_type'])\n",
    "tfidf_vec_validation = tfidf_trans.transform(validation_data['body'] + validation_data['title'] + validation_data['majority_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "IgCMj1cTYBOY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negative       0.28      0.20      0.24       282\n",
      "      neutral       0.73      0.77      0.75      2514\n",
      "     positive       0.52      0.52      0.52      1102\n",
      "very negative       0.67      0.06      0.11        32\n",
      "very positive       0.17      0.05      0.07        86\n",
      "\n",
      "     accuracy                           0.64      4016\n",
      "    macro avg       0.47      0.32      0.34      4016\n",
      " weighted avg       0.63      0.64      0.63      4016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_onehot_model = LogisticRegression(C=C, class_weight=class_weight, max_iter = 1000)\n",
    "lr_onehot_model.fit(tfidf_train, train_data['sentiment.polarity'])\n",
    "preds = lr_onehot_model.predict(tfidf_test)\n",
    "print(classification_report(test_data['sentiment.polarity'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TaD_Fucker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
